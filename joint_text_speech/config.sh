exp_name=debug
TRANSFORMERS_OFFLINE=1 python -u /mnt/matylda6/ivendrame/wavlm_connector_lm/scripts/joint_text_speech/train_asr.py --train_encoder --output_dir /mnt/matylda6/ivendrame/wavlm_connector_lm/experiments/text_input/$exp_name/outputs --train_asr_dir /mnt/matylda6/ivendrame/data/librispeech_asr_data/trans_shuf.txt --train_text_dir /mnt/matylda6/ivendrame/data/librispeech_shuf.txt --val_dir /mnt/matylda6/ivendrame/data/librispeech_asr_data_dev_test/all_dev.txt --log_dir /mnt/matylda6/ivendrame/wavlm_connector_lm/tensorboard/connector_runs/$exp_name --tokenizer_dir /mnt/matylda6/ivendrame/wavlm_connector_lm/tokenizer --audio_dir /mnt/matylda6/ivendrame/data/librispeech_asr_data_all_flacs --hidden_size 2048 --num_heads 12 --num_layers 12 --ff_size 2048 --peak_lr 1e-4 --min_lr_ratio 0.1 --early_stopping_patience 3 --max_steps 600_000 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --dataloader_num_workers 2 --validation_steps 100 --save_steps 10_000 --accumulation_steps 1 --weight_decay 0
